{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "wine = load_wine()\n",
    "\n",
    "digits = load_digits()\n",
    "\n",
    "breast_cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 필요한 모듈 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**모델 모듈**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier  #의사결정나무\n",
    "from sklearn.ensemble import RandomForestClassifier  #랜덤포레스트\n",
    "from sklearn import svm  #SVM\n",
    "from sklearn.linear_model import SGDClassifier  #SGD\n",
    "from sklearn.linear_model import LogisticRegression #로지스틱회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 평가\n",
    "from sklearn.metrics import classification_report  \n",
    "from sklearn.metrics import accuracy_score  #정확도\n",
    "from sklearn.metrics import confusion_matrix #오차행렬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 손글씨 이미지 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 이해하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature data 지정\n",
    "digits_data = digits.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits_data.shape    # digit 데이터의 개수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label 데이터 지정\n",
    "digits_label = digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#target names 출력\n",
    "digits.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, ..., 8, 9, 8])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pixel_0_0',\n",
       " 'pixel_0_1',\n",
       " 'pixel_0_2',\n",
       " 'pixel_0_3',\n",
       " 'pixel_0_4',\n",
       " 'pixel_0_5',\n",
       " 'pixel_0_6',\n",
       " 'pixel_0_7',\n",
       " 'pixel_1_0',\n",
       " 'pixel_1_1',\n",
       " 'pixel_1_2',\n",
       " 'pixel_1_3',\n",
       " 'pixel_1_4',\n",
       " 'pixel_1_5',\n",
       " 'pixel_1_6',\n",
       " 'pixel_1_7',\n",
       " 'pixel_2_0',\n",
       " 'pixel_2_1',\n",
       " 'pixel_2_2',\n",
       " 'pixel_2_3',\n",
       " 'pixel_2_4',\n",
       " 'pixel_2_5',\n",
       " 'pixel_2_6',\n",
       " 'pixel_2_7',\n",
       " 'pixel_3_0',\n",
       " 'pixel_3_1',\n",
       " 'pixel_3_2',\n",
       " 'pixel_3_3',\n",
       " 'pixel_3_4',\n",
       " 'pixel_3_5',\n",
       " 'pixel_3_6',\n",
       " 'pixel_3_7',\n",
       " 'pixel_4_0',\n",
       " 'pixel_4_1',\n",
       " 'pixel_4_2',\n",
       " 'pixel_4_3',\n",
       " 'pixel_4_4',\n",
       " 'pixel_4_5',\n",
       " 'pixel_4_6',\n",
       " 'pixel_4_7',\n",
       " 'pixel_5_0',\n",
       " 'pixel_5_1',\n",
       " 'pixel_5_2',\n",
       " 'pixel_5_3',\n",
       " 'pixel_5_4',\n",
       " 'pixel_5_5',\n",
       " 'pixel_5_6',\n",
       " 'pixel_5_7',\n",
       " 'pixel_6_0',\n",
       " 'pixel_6_1',\n",
       " 'pixel_6_2',\n",
       " 'pixel_6_3',\n",
       " 'pixel_6_4',\n",
       " 'pixel_6_5',\n",
       " 'pixel_6_6',\n",
       " 'pixel_6_7',\n",
       " 'pixel_7_0',\n",
       " 'pixel_7_1',\n",
       " 'pixel_7_2',\n",
       " 'pixel_7_3',\n",
       " 'pixel_7_4',\n",
       " 'pixel_7_5',\n",
       " 'pixel_7_6',\n",
       " 'pixel_7_7']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.feature_names\n",
    "#픽셀로 표현되어 있음 -> 데이터프레임 데이터가 아니라 이미지라서"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _digits_dataset:\n",
      "\n",
      "Optical recognition of handwritten digits dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 5620\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n"
     ]
    }
   ],
   "source": [
    "print(digits.DESCR)\n",
    "\n",
    "# 8x8 이미지가 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits_data[0].shape\n",
    "#64개의 array\n",
    "#(8x8)크기의 이미지를 일렬로 쭉 펴놓은 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 그려보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAADyUlEQVR4nO3dUVFjaRRG0T9TYyAWggSwkkgACSABL5FAJBALSCAS7higeZo6vZte6zF5+KiEXbeKB85u27YF9Pzzu38A4GvihChxQpQ4IUqcEPXvd2/udrsf+afc4/E4uvf6+jq2dblcxrZeXl7Gtm6329jWtG3bdl+97skJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEqG/PMfxUk+cR1lrrcDiMbe33+7Gtz8/Psa3T6TS2tdZa5/N5dO8rnpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IypxjuL+/H9uaPI+w1lp3d3djWx8fH2Nbb29vY1uTvx9rOccAfEOcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiMrcStnv92Nb1+t1bGut2fslk6Y/x7+NJydEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROi/spzDJfLZWzrJ5v8zm6329hWhScnRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTojLnGCb/3f79/f3Y1rTJEwmTn+P5fB7bqvDkhChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQtRu27Zfv7nb/frN/9nhcJiaWu/v72Nba6319PQ0tnU8Hse2Jr+zh4eHsa1p27btvnrdkxOixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oSozK2USY+Pj6N7z8/PY1vX63Vs63Q6jW39ZG6lwB9GnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBD17TkG4Pfx5IQocUKUOCFKnBAlTogSJ0T9ByioUst9Wxj9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 0번 째 데이터 그려보기\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.imshow(digits.data[0].reshape(8, 8), cmap='gray')\n",
    "                                #일렬로 펴진 64개의 데이터를 reshape 해줌\n",
    "plt.axis('off')\n",
    "#출력할 때 눈금을 없애줌\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 0~9 번째 데이터 그려보기\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(digits.data[i].reshape(8, 8), cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train, test 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(digits_data, digits_label,\n",
    "                                                   test_size = 0.2, random_state= 1,\n",
    "                                                   stratify=digits_label)\n",
    "\n",
    "#test_size -> train과 test 데이터의 비율을 맞춰줌. 지금은 train:test = 8:2\n",
    "#random_state -> train 데이터와 test 데이터를 분리하는데 적용되는 랜덤성을 결정. \n",
    "#                내가 실험한 결과를 다른 사람의 컴퓨터에서도 재현가능(reproducible) 하게 하기 위해서도 필요\n",
    "#stratify -> 데이터 셋이 작아서 큰 차이는 없겠지만 학습데이터와 테스트 데이터에 들어가는 라벨의 비율이 비슷하게 만들어줌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = DecisionTreeClassifier(random_state = 1004)\n",
    "decision_tree.fit(x_train, y_train)\n",
    "y_pred_decision = decision_tree.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(random_state = 1004)\n",
    "random_forest.fit(x_train, y_train)\n",
    "y_pred_random = random_forest.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = svm.SVC(random_state = 1004)\n",
    "svm_model.fit(x_train, y_train)\n",
    "y_pred_svm = svm_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGDClassifier(random_state = 1004)\n",
    "sgd.fit(x_train, y_train)\n",
    "y_pred_sgd = sgd.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kyungbeen/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(x_train, y_train)\n",
    "y_pred_lr = lr.predict(x_test)\n",
    "# 'max_iter'까지 학습했으나 아직 정답에 수렴하지 못한 상태"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**구글링으로 iterator의 수를 늘려야 한다는 해결방안을 통해 경고문 해결**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state = 1004, max_iter = 4000)\n",
    "                                            #숫자를 늘리니까 셀 작동 시간이 늘어남\n",
    "lr.fit(x_train, y_train)\n",
    "y_pred_lr = lr.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 문제의 경우, 손글씨 숫자를 얼마나 정확하게 알아보느냐에 따라 모델의 성능이 평가되어야 한다고 생각한다. \n",
    "\n",
    "금융 문제나 시험과 같은 민감한 문제가 아닌 단순 이미지 인식 문제이기 때문이다. \n",
    "\n",
    "그렇기 때문에 전체 데이터 중 올바르게 판단한 데이터 개수의 비율인 Accuracy가 이 문제에 적합한 평가지표라고 판단했다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정확도 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('DecisionTree', 0.8444444444444444),\n",
       " ('RandomForest', 0.9777777777777777),\n",
       " ('SVM', 0.9916666666666667),\n",
       " ('SGD', 0.9583333333333334),\n",
       " ('LogisticRegression', 0.9583333333333334)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "preds = [y_pred_decision, y_pred_random, y_pred_svm, y_pred_sgd, y_pred_lr]\n",
    "accuracy_scores = []\n",
    "for i in preds:\n",
    "    accuracy = accuracy_score(y_test, i)\n",
    "    accuracy_scores.append(accuracy)\n",
    "\n",
    "#결과를 편하게 비교하기 위해 값들에 이름을 붙여줌\n",
    "name = ['DecisionTree', 'RandomForest', 'SVM', 'SGD', 'LogisticRegression']\n",
    "\n",
    "compare = list(zip(name, accuracy_scores))\n",
    "compare\n",
    "\n",
    "#결과를 보았을 때, SVM이 가장 잘 나옴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**정확도의 오류를 피하기 위해 collection 모듈을 사용하여 배열의 항목 당 개수를 구함**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({3: 183, 1: 182, 5: 182, 4: 181, 6: 181, 9: 180, 7: 179, 0: 178, 2: 177, 8: 174})\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "print(collections.Counter(digits_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        36\n",
      "           1       0.97      1.00      0.99        36\n",
      "           2       1.00      1.00      1.00        35\n",
      "           3       1.00      1.00      1.00        37\n",
      "           4       1.00      1.00      1.00        36\n",
      "           5       1.00      0.95      0.97        37\n",
      "           6       0.97      1.00      0.99        36\n",
      "           7       1.00      1.00      1.00        36\n",
      "           8       1.00      0.97      0.99        35\n",
      "           9       0.97      1.00      0.99        36\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 정확도의 오류를 알아보기 위해 collection 모듈을 불러와 digits_label의 항목당 개수를 확인해 보았고, \n",
    " \n",
    " 고르게 분포되어있다는 것을 확인했다. \n",
    " \n",
    " Decision Tree를 제외한 모든 모델이 0.95 이상의 성능을 보이며 대체적으로 잘 학습되었다는 것을 알 수 있다. \n",
    " \n",
    " 따라서 해당 문제의 평가 지표는 정확도(Accuracy)이고, 가장 성능이 높은 모델은 SVM이다. \n",
    " \n",
    " 또한  재현율, 정밀도, F1-score 모두 높은 성능을 보였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 와인 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 이해하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_data = wine.data   #feature 지정\n",
    "wine_label = wine.target    #label 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 13)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_data.shape    # wine 데이터의 개수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['class_0', 'class_1', 'class_2'], dtype='<U7')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.target_names\n",
    "#클래스는 총 3개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 13)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_data.shape\n",
    "# 13개의 feature\n",
    "# 178개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 Describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _wine_dataset:\n",
      "\n",
      "Wine recognition dataset\n",
      "------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 178 (50 in each of three classes)\n",
      "    :Number of Attributes: 13 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      " \t\t- Alcohol\n",
      " \t\t- Malic acid\n",
      " \t\t- Ash\n",
      "\t\t- Alcalinity of ash  \n",
      " \t\t- Magnesium\n",
      "\t\t- Total phenols\n",
      " \t\t- Flavanoids\n",
      " \t\t- Nonflavanoid phenols\n",
      " \t\t- Proanthocyanins\n",
      "\t\t- Color intensity\n",
      " \t\t- Hue\n",
      " \t\t- OD280/OD315 of diluted wines\n",
      " \t\t- Proline\n",
      "\n",
      "    - class:\n",
      "            - class_0\n",
      "            - class_1\n",
      "            - class_2\n",
      "\t\t\n",
      "    :Summary Statistics:\n",
      "    \n",
      "    ============================= ==== ===== ======= =====\n",
      "                                   Min   Max   Mean     SD\n",
      "    ============================= ==== ===== ======= =====\n",
      "    Alcohol:                      11.0  14.8    13.0   0.8\n",
      "    Malic Acid:                   0.74  5.80    2.34  1.12\n",
      "    Ash:                          1.36  3.23    2.36  0.27\n",
      "    Alcalinity of Ash:            10.6  30.0    19.5   3.3\n",
      "    Magnesium:                    70.0 162.0    99.7  14.3\n",
      "    Total Phenols:                0.98  3.88    2.29  0.63\n",
      "    Flavanoids:                   0.34  5.08    2.03  1.00\n",
      "    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\n",
      "    Proanthocyanins:              0.41  3.58    1.59  0.57\n",
      "    Colour Intensity:              1.3  13.0     5.1   2.3\n",
      "    Hue:                          0.48  1.71    0.96  0.23\n",
      "    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\n",
      "    Proline:                       278  1680     746   315\n",
      "    ============================= ==== ===== ======= =====\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML Wine recognition datasets.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
      "\n",
      "The data is the results of a chemical analysis of wines grown in the same\n",
      "region in Italy by three different cultivators. There are thirteen different\n",
      "measurements taken for different constituents found in the three types of\n",
      "wine.\n",
      "\n",
      "Original Owners: \n",
      "\n",
      "Forina, M. et al, PARVUS - \n",
      "An Extendible Package for Data Exploration, Classification and Correlation. \n",
      "Institute of Pharmaceutical and Food Analysis and Technologies,\n",
      "Via Brigata Salerno, 16147 Genoa, Italy.\n",
      "\n",
      "Citation:\n",
      "\n",
      "Lichman, M. (2013). UCI Machine Learning Repository\n",
      "[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\n",
      "School of Information and Computer Science. \n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  (1) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  Comparison of Classifiers in High Dimensional Settings, \n",
      "  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Technometrics). \n",
      "\n",
      "  The data was used with many others for comparing various \n",
      "  classifiers. The classes are separable, though only RDA \n",
      "  has achieved 100% correct classification. \n",
      "  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \n",
      "  (All results using the leave-one-out technique) \n",
      "\n",
      "  (2) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \n",
      "  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Journal of Chemometrics).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(wine.DESCR)\n",
    "# 총 13개의 feature 모두 수치형 데이터\n",
    "# 결측치가 없음\n",
    "# 같은 이탈리아지방에서 재배되었지만 경작한 사람이 다름\n",
    "# 클래스의 의미가 단순 분류. 순위를 나타내는 것은 아닌 것으로 생각됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train, test 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2_train, x2_test, y2_train, y2_test = train_test_split(wine_data, wine_label,\n",
    "                                                   test_size = 0.2, random_state= 1,\n",
    "                                                   stratify=wine_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = DecisionTreeClassifier(random_state = 8282)\n",
    "decision_tree.fit(x2_train, y2_train)\n",
    "y2_pred_decision = decision_tree.predict(x2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(random_state = 8282)\n",
    "random_forest.fit(x2_train, y2_train)\n",
    "y2_pred_random = random_forest.predict(x2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = svm.SVC(random_state = 8282)\n",
    "svm_model.fit(x2_train, y2_train)\n",
    "y2_pred_svm = svm_model.predict(x2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGDClassifier(random_state = 8282)\n",
    "sgd.fit(x2_train, y2_train)\n",
    "y2_pred_sgd = sgd.predict(x2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state = 8282, max_iter = 4000)\n",
    "lr.fit(x2_train, y2_train)\n",
    "y2_pred_lr = lr.predict(x2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**정확도의 오류를 피하기 위해 collection 모듈을 사용하여 배열의 항목 당 개수를 구함**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 71, 0: 59, 2: 48})\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "print(collections.Counter(wine_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 문제의 경우, 클래스가 3개로 나뉘어 있지만 데이터 해설을 보았을 때 와인의 순위를 나누는 것이 아닌 단순 다중 분류 문제이다.\n",
    "\n",
    "그렇기 때문에 음성인데 양성으로 판단하는 경우가 적어야 한다거나, 양성인데 음성으로 판단하는 경우가 적어야 한다는 이슈는 해당되지 않는다고 생각한다.\n",
    "\n",
    "또한 label의 분포 또한 편차가 있지만 불균형의 정도가 심하지 않기 때문에 이 문제의 평가지표를 Accuracy(정확도)로 선택했다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정확도 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('DecisionTree', 0.9444444444444444),\n",
       " ('RandomForest', 1.0),\n",
       " ('SVM', 0.6111111111111112),\n",
       " ('SGD', 0.5555555555555556),\n",
       " ('LogisticRegression', 1.0)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "preds2 = [y2_pred_decision, y2_pred_random, y2_pred_svm, y2_pred_sgd, y2_pred_lr]\n",
    "accuracy2_scores = []\n",
    "for i in preds2:\n",
    "    accuracy2 = accuracy_score(y2_test, i)\n",
    "    accuracy2_scores.append(accuracy2)\n",
    "\n",
    "#결과를 편하게 비교하기 위해 값들에 이름을 붙여줌\n",
    "name = ['DecisionTree', 'RandomForest', 'SVM', 'SGD', 'LogisticRegression']\n",
    "\n",
    "compare2 = list(zip(name, accuracy2_scores))\n",
    "compare2\n",
    "\n",
    "#결과를 보았을 때, RandomForest와 LogisticRegression이 가장 잘 나옴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest 정밀도, 재현율, F1-score 확인**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        12\n",
      "           1       1.00      1.00      1.00        14\n",
      "           2       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y2_test, y2_pred_random))\n",
    "# 모두 1로 정확한 예측이 진행된 것을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression 정밀도, 재현율, F1-score 확인**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        12\n",
      "           1       1.00      1.00      1.00        14\n",
      "           2       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y2_test, y2_pred_lr))\n",
    "# 모두 1로 정확한 예측이 진행된 것을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RandomForest, Logistic Regression 과 SGD, SVM의 성능 격차가 커서 확인해 보았다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SGD 정밀도, 재현율, F1-score 확인**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      1.00      0.65        12\n",
      "           1       0.67      0.43      0.52        14\n",
      "           2       1.00      0.20      0.33        10\n",
      "\n",
      "    accuracy                           0.56        36\n",
      "   macro avg       0.72      0.54      0.50        36\n",
      "weighted avg       0.70      0.56      0.51        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y2_test, y2_pred_sgd))\n",
    "\n",
    "# 2에 대한 precision이 1인 것으로 보아,\n",
    "# 2라고 예측한 것이 모두 실제로 2이지만, 2라고 예측하지 않은 것 중에 2가 있을 확률이 높을 것이다.\n",
    "# 0에 대한 recall이 1인 것으로 보아,\n",
    "# 실제로 0인 것 중에 0이라고 예측한 것의 개수가 같지만, 0이 아닌 것 중에 0이라고 예측한 확률이 높을 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVM 정밀도, 재현율, F1-score 확인**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92        12\n",
      "           1       0.54      0.50      0.52        14\n",
      "           2       0.36      0.40      0.38        10\n",
      "\n",
      "    accuracy                           0.61        36\n",
      "   macro avg       0.61      0.61      0.61        36\n",
      "weighted avg       0.62      0.61      0.61        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y2_test, y2_pred_svm))\n",
    "\n",
    "# precision, recall, f1-score 모두 0에 대한 예측도가 높지만\n",
    "# 1, 2에 대한 예측도는 낮다.\n",
    "# 3개의 label 중 1의 개수가 가장 많은데 0에 대한 예측도가 높은 게 신기하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest와 Logistic Regression의 예측 정확도가 1.0으로 label을 정확히 예측한 것을 알 수 있다.\n",
    "\n",
    "모델의 성능이 대체적으로 좋았던 손글씨 분류 문제와는 다르게 SVM과 SGD의 성능이 훨씬 떨어졌다.\n",
    "\n",
    "SVM의 경우 이진 분류 문제에 특화되어 있는 선형 분류 알고리즘이기 때문에 이러한 결과가 나온 것으로 예상되며,\n",
    "\n",
    "SGD의 경우 데이터의 수가 적기 때문에 반복이 충분하게 이루어져 그만큼 노이즈가 생성된 것으로 예상된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 유방암 여부 진단"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 이해하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer_data = breast_cancer.data   #feature 지정\n",
    "breast_cancer_label = breast_cancer.target    #label 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_cancer_data.shape    # breast_cancer 데이터의 개수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['malignant', 'benign'], dtype='<U9')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_cancer.target_names\n",
    "# malignant -> 악성 \n",
    "# benign -> 양성(괜찮음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "       'smoothness error', 'compactness error', 'concavity error',\n",
       "       'concave points error', 'symmetry error',\n",
       "       'fractal dimension error', 'worst radius', 'worst texture',\n",
       "       'worst perimeter', 'worst area', 'worst smoothness',\n",
       "       'worst compactness', 'worst concavity', 'worst concave points',\n",
       "       'worst symmetry', 'worst fractal dimension'], dtype='<U23')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_cancer.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 Describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry\n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        worst/largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 0 is Mean Radius, field\n",
      "        10 is Radius SE, field 20 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    }
   ],
   "source": [
    "print(breast_cancer.DESCR)\n",
    "# 569개의 데이터\n",
    "# 30개의 feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train, test 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3_train, x3_test, y3_train, y3_test = train_test_split(breast_cancer_data, breast_cancer_label,\n",
    "                                                       test_size = 0.2, random_state = 1,\n",
    "                                                       stratify = breast_cancer_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = DecisionTreeClassifier(random_state = 5959)\n",
    "decision_tree.fit(x3_train, y3_train)\n",
    "y3_pred_decision = decision_tree.predict(x3_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(random_state = 5959)\n",
    "random_forest.fit(x3_train, y3_train)\n",
    "y3_pred_random = random_forest.predict(x3_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "svm_model = svm.SVC(random_state = 5959)\n",
    "svm_model.fit(x3_train, y3_train)\n",
    "y3_pred_svm = svm_model.predict(x3_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGDClassifier(random_state = 5959)\n",
    "sgd.fit(x3_train, y3_train)\n",
    "y3_pred_sgd = sgd.predict(x3_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state = 5959, max_iter = 4000)\n",
    "                                            # 경고문구 해결\n",
    "lr.fit(x3_train, y3_train)\n",
    "y3_pred_lr = lr.predict(x3_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 문제의 경우, 양성(malignant, True)인 경우 음성(benign, False)으로 판단할 경우가 적어야 한다.\n",
    "\n",
    "그렇기 때문에 평가지표는 Recall(재현율)을 사용했다.\n",
    "\n",
    "재현율만 비교하면 되기 때문에 classification_report를 사용하지 않고,\n",
    "\n",
    "사이킷런의 metrics를 사용하여 재현율을 구했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('DecisionTree', 0.9861111111111112),\n",
       " ('RandomForest', 0.9722222222222222),\n",
       " ('SVM', 0.9722222222222222),\n",
       " ('SGD', 0.9444444444444444),\n",
       " ('LogisticRegression', 0.9861111111111112)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "preds3 = [y3_pred_decision, y3_pred_random, y3_pred_svm, y3_pred_sgd, y3_pred_lr]\n",
    "\n",
    "recalls = []\n",
    "for i in preds3:\n",
    "    recalls.append(metrics.recall_score(y3_test,i))\n",
    "\n",
    "#결과를 편하게 비교하기 위해 값들에 이름을 붙여줌\n",
    "name = ['DecisionTree', 'RandomForest', 'SVM', 'SGD', 'LogisticRegression']\n",
    "\n",
    "compare_recall = list(zip(name, recalls))\n",
    "compare_recall "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모든 모델이 좋은 성능을 보이지만 Decision Tree와 Logistic Regression의 성능이 가장 높다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 회고"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stratify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_test_split을 사용하면서 stratify 를 데이터의 label로 설정해주었다. \n",
    "\n",
    "stratify는 train셋과 test셋을 나눌 때 class의 비율을 고려해서 나누게 만들어준다. \n",
    "\n",
    "본 과제에서 사용되는 데이터의 양이 적기 때문에 stratify의 역할이 미미하지만, \n",
    "\n",
    "대용량의 데이터를 사용해 모델링을 하게될 경우 중요한 부분이기 때문이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### max_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression 모델링을 할 때 \n",
    "\n",
    "'Increase the number of iterations (max_iter) or scale the data'와 같은 경고창이 출력되었다. \n",
    "\n",
    "'max_iter'까지 학습했으나 아직 정답에 수렴하지 못한 상태인 것을 확인하고 \n",
    "\n",
    "구글링을 통해 모델 안의 max_iter 값을 상향조정해주었더니 문제가 해결되었다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델의 성능을 한 눈에 비교하기 위해 모델과 예측값을 담은 리스트를 각각 만든 후\n",
    "\n",
    "zip 함수를 사용하여 모델에 해당하는 예측값을 한 튜플에 넣었다.\n",
    "\n",
    "원래는 DataFrame을 만들고 싶었으나, 5x1 리스트에 컬럼을 지정할 수 없다는 에러가 계속되었다.\n",
    "\n",
    "그래서 5x1 리스트를 array 형태로 만들어 5x1의 형태로 만든 후 컬럼명을 모델의 이름으로 지정하려 하였으나\n",
    "\n",
    "에러가 계속되어 zip 함수를 사용하게 되었다.\n",
    "\n",
    "원하던 모양은 아니었지만 한 눈에 비교할 수 있어서 나름 만족했다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "클래스 라벨의 분포가 불균형할 경우, 정확도가 높아도 모델 학습이 잘 되었는지 확인하는 적절한 평가지표가 되기 어렵다.\n",
    "\n",
    "digits 데이터와 wine 데이터에 맞는 평가지표는 정확도라고 판단했기 때문에 클래스 라벨의 분포를 확인해야 했다. \n",
    "\n",
    "따라서 collection 모듈을 사용하여 클래스 라벨 당 개수를 구했다.\n",
    "\n",
    "값은 딕셔너리 형태로 출력되었고, digits 데이터터 wine 데이터 모두 클래스 라벨이 고르게 분포되어있음을 확인했다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "breast_cancer 데이터의 경우 재현율(recall)이 적절한 모델의 평가지표이므로\n",
    "\n",
    "정밀도, F1-score가 함께 출력되는 classification_report를 사용하지 않고\n",
    "\n",
    "재현율만 따로 구할 수 있는 사이킷런의 metrics를 사용했다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 후기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델간의 성능 비교를 위해 각 모델의 하이퍼 파라미터 조정을 따로 하지 않았다. \n",
    "\n",
    "각 모델이 가지고 있는 하이퍼 파라미터의 종류도 다르고, 각자 다른 값으로 조정하면 명확한 비교가 어려울 것이라고 생각했기 때문이다. \n",
    "\n",
    "Logistic Regression의 경우 max_iter 값을 조정했지만 이는 모델의 성능 향상이 아닌 모델이 끝까지 실행되기 위함이다. \n",
    "\n",
    "이번 과제에 사용한 모델들은 그동안 머신러닝 과제를 진행하면서 한 번씩은 다 사용해본 모델들인데도,\n",
    "\n",
    "모델 별 정보를 제대로 잘 알고 있지 못해서 LMS창의 모델 설명 부분을 계속해서 보면서 과제를 진행했다.\n",
    "\n",
    "원래도 기초가 부실하다고 생각하긴 했지만 이렇게 정말 부족하다는 사실을 마주하니 씁쓸했다.\n",
    "\n",
    "SVM 모델명을 svm으로 하는 어이없는 실수를 했지만 뭐가 잘못됐는지 모르겠어서 조원분들께 도움을 구했다.\n",
    "\n",
    "2분도 안돼서 잘못된 부분을 알려주셨고 혼자 계속 고민하던 부분이 한 방에 해결되어서 시원하기도 민망하기도 했다.\n",
    "\n",
    "하지만 이런 경험으로 아이펠의 장점을 한 번 더 깨닫게 되었다.\n",
    "\n",
    "이런게 집단지성의 힘인걸까..? 혼자 공부할 땐 모르는 부분은 에러가 나지 않는 이상 그냥 넘어간 적이 많은데 \n",
    "\n",
    "이렇게 얘기를 한 번 하면서 사소한 것들도 해결하고 넘어갈 수 있게 되었다. \n",
    "\n",
    "아직은 혼자 공부하는 게 몸에 배어있지만 그래도 다른 사람들과 함께 공부하는 장점을 하나씩 알아가는 느낌이다. \n",
    "\n",
    "나중에 더 어려운 과제를 진행하면 이러한 장점이 극대화될 것이라고 기대된다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**향후 과제**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터의 개수에 맞는 Logistic Regression 의 max_iter 값 탐색\n",
    "- zip 함수가 아닌 데이터 프레임으로 만들기\n",
    "- 좀 더 자세히 모델 별 특성 파악 \n",
    "- 오차행렬 시각화(Heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
